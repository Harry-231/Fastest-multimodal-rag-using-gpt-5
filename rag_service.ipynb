{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b653f10",
   "metadata": {},
   "source": [
    "# MODUALR RAG WITH QDRANT , GPT-5 AND PyMuPDF , LLAMAINDEX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184eb431",
   "metadata": {},
   "source": [
    "## Parsing the pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9862e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "@dataclass\n",
    "class ExtractedContent:\n",
    "    \"\"\"Container for extracted PDF content\"\"\"\n",
    "    texts: List[Dict[str, Any]]\n",
    "    tables: List[Dict[str, Any]]\n",
    "    images: List[Dict[str, Any]]\n",
    "\n",
    "class PDFParser:\n",
    "    \"\"\"Simple PDF parser for extracting text, tables, and images\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str = \"extracted\", save_as_markdown: bool = True, use_ocr: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize PDF Parser\n",
    "        \n",
    "        Args:\n",
    "            output_dir: Directory to save extracted content\n",
    "            save_as_markdown: Whether to save text content as markdown\n",
    "            use_ocr: Whether to use OCR for text extraction\n",
    "        \"\"\"\n",
    "        self.output_dir = output_dir\n",
    "        self.save_as_markdown = save_as_markdown\n",
    "        self.use_ocr = use_ocr\n",
    "        \n",
    "        # Create output directories\n",
    "        self.text_dir = os.path.join(output_dir, \"texts\")\n",
    "        self.table_dir = os.path.join(output_dir, \"tables\")\n",
    "        self.image_dir = os.path.join(output_dir, \"images\")\n",
    "        \n",
    "        os.makedirs(self.text_dir, exist_ok=True)\n",
    "        os.makedirs(self.table_dir, exist_ok=True)\n",
    "        os.makedirs(self.image_dir, exist_ok=True)\n",
    "    \n",
    "    def parse_pdf(self, pdf_path: str) -> ExtractedContent:\n",
    "        \"\"\"Parse a single PDF file\"\"\"\n",
    "        results = self.parse_pdfs([pdf_path])\n",
    "        return results.get(pdf_path, ExtractedContent([], [], []))\n",
    "    \n",
    "    def parse_pdfs(self, pdf_paths: List[str]) -> Dict[str, ExtractedContent]:\n",
    "        \"\"\"Parse multiple PDF files\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for pdf_path in pdf_paths:\n",
    "            print(f\"Processing: {pdf_path}\")\n",
    "            try:\n",
    "                content = self._extract_content(pdf_path)\n",
    "                results[pdf_path] = content\n",
    "                self._save_to_files(pdf_path, content)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {pdf_path}: {e}\")\n",
    "                results[pdf_path] = ExtractedContent([], [], [])\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _extract_content(self, pdf_path: str) -> ExtractedContent:\n",
    "        \"\"\"Extract content from a PDF file\"\"\"\n",
    "        texts = []\n",
    "        tables = []\n",
    "        images = []\n",
    "        \n",
    "        doc = pymupdf.open(pdf_path)\n",
    "        \n",
    "        for page_num, page in enumerate(doc, 1):\n",
    "            # Extract text\n",
    "            if self.use_ocr:\n",
    "                text_content = self._extract_text_with_ocr(page)\n",
    "            else:\n",
    "                text_content = page.get_text()\n",
    "            \n",
    "            if text_content.strip():\n",
    "                texts.append({\n",
    "                    'page': page_num,\n",
    "                    'content': text_content,\n",
    "                    'metadata': {\n",
    "                        'source': pdf_path,\n",
    "                        'extraction_method': 'ocr' if self.use_ocr else 'native'\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "            # Extract tables\n",
    "            try:\n",
    "                table_finder = page.find_tables()\n",
    "                for table_idx, table in enumerate(table_finder.tables):\n",
    "                    table_data = table.extract()\n",
    "                    if table_data:\n",
    "                        tables.append({\n",
    "                            'page': page_num,\n",
    "                            'table_data': table_data,\n",
    "                            'metadata': {\n",
    "                                'source': pdf_path,\n",
    "                                'table_index': table_idx\n",
    "                            }\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"Could not extract tables from page {page_num}: {e}\")\n",
    "            \n",
    "            # Extract images\n",
    "            image_list = page.get_images(full=True)\n",
    "            for img_index, img in enumerate(image_list):\n",
    "                try:\n",
    "                    xref = img[0]\n",
    "                    base_image = doc.extract_image(xref)\n",
    "                    img_bytes = base_image[\"image\"]\n",
    "                    img_ext = base_image[\"ext\"]\n",
    "                    \n",
    "                    images.append({\n",
    "                        'page': page_num,\n",
    "                        'image_bytes': img_bytes,\n",
    "                        'metadata': {\n",
    "                            'source': pdf_path,\n",
    "                            'index': img_index,\n",
    "                            'format': img_ext,\n",
    "                            'size_bytes': len(img_bytes)\n",
    "                        }\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not extract image {img_index} from page {page_num}: {e}\")\n",
    "        \n",
    "        doc.close()\n",
    "        return ExtractedContent(texts=texts, tables=tables, images=images)\n",
    "    \n",
    "    def _extract_text_with_ocr(self, page):\n",
    "        \"\"\"Extract text using OCR\"\"\"\n",
    "        try:\n",
    "            # Render page to image\n",
    "            mat = pymupdf.Matrix(2, 2)  # 2x zoom for better OCR\n",
    "            pix = page.get_pixmap(matrix=mat)\n",
    "            img_data = pix.tobytes(\"png\")\n",
    "            \n",
    "            # Perform OCR\n",
    "            image = Image.open(io.BytesIO(img_data))\n",
    "            ocr_text = pytesseract.image_to_string(image, lang='eng')\n",
    "            return ocr_text\n",
    "        except Exception as e:\n",
    "            print(f\"OCR failed, falling back to native extraction: {e}\")\n",
    "            return page.get_text()\n",
    "    \n",
    "    def _save_to_files(self, pdf_path: str, content: ExtractedContent):\n",
    "        \"\"\"Save extracted content to files\"\"\"\n",
    "        pdf_name = Path(pdf_path).stem\n",
    "        \n",
    "        # Save texts\n",
    "        if content.texts:\n",
    "            if self.save_as_markdown:\n",
    "                text_file = os.path.join(self.text_dir, \"texts.md\")\n",
    "                mode = 'a' if os.path.exists(text_file) else 'w'\n",
    "                with open(text_file, mode, encoding='utf-8') as f:\n",
    "                    f.write(f\"# Extracted Text from {pdf_name}\\n\\n\")\n",
    "                    for text_data in content.texts:\n",
    "                        f.write(f\"## Page {text_data['page']}\\n\\n\")\n",
    "                        f.write(text_data['content'])\n",
    "                        f.write(\"\\n\\n---\\n\\n\")\n",
    "            else:\n",
    "                text_file = os.path.join(self.text_dir, \"texts.txt\")\n",
    "                mode = 'a' if os.path.exists(text_file) else 'w'\n",
    "                with open(text_file, mode, encoding='utf-8') as f:\n",
    "                    for text_data in content.texts:\n",
    "                        f.write(f\"=== {pdf_name} - Page {text_data['page']} ===\\n\")\n",
    "                        f.write(text_data['content'])\n",
    "                        f.write(\"\\n\\n\")\n",
    "        \n",
    "        # Save tables\n",
    "        if content.tables:\n",
    "            existing_tables = [f for f in os.listdir(self.table_dir) if f.startswith('table_') and f.endswith('.md')]\n",
    "            next_num = len(existing_tables) + 1\n",
    "            \n",
    "            for table_data in content.tables:\n",
    "                table_file = os.path.join(self.table_dir, f\"table_{next_num}.md\")\n",
    "                with open(table_file, 'w', encoding='utf-8') as f:\n",
    "                    f.write(f\"# Table {next_num}\\n\")\n",
    "                    f.write(f\"**Source:** {pdf_name}\\n\")\n",
    "                    f.write(f\"**Page:** {table_data['page']}\\n\\n\")\n",
    "                    f.write(self._table_to_markdown(table_data['table_data']))\n",
    "                next_num += 1\n",
    "        \n",
    "        # Save images\n",
    "        if content.images:\n",
    "            for img_data in content.images:\n",
    "                img_filename = f\"images_p{img_data['page']}_img{img_data['metadata']['index']}.{img_data['metadata']['format']}\"\n",
    "                img_path = os.path.join(self.image_dir, img_filename)\n",
    "                with open(img_path, 'wb') as f:\n",
    "                    f.write(img_data['image_bytes'])\n",
    "    \n",
    "    def _table_to_markdown(self, table_data: List[List[str]]) -> str:\n",
    "        \"\"\"Convert table data to markdown format\"\"\"\n",
    "        if not table_data or not table_data[0]:\n",
    "            return \"\"\n",
    "        \n",
    "        markdown = []\n",
    "        \n",
    "        # Header\n",
    "        markdown.append(\"| \" + \" | \".join(str(cell) for cell in table_data[0]) + \" |\")\n",
    "        markdown.append(\"|\" + \"|\".join([\"---\"] * len(table_data[0])) + \"|\")\n",
    "        \n",
    "        # Rows\n",
    "        for row in table_data[1:]:\n",
    "            markdown.append(\"| \" + \" | \".join(str(cell) for cell in row) + \" |\")\n",
    "        \n",
    "        return \"\\n\".join(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d0d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PDFParser(\n",
    "        output_dir=\"extracted\",\n",
    "        save_as_markdown=True,\n",
    "        use_ocr=False  # Set to True if you need OCR\n",
    "    )\n",
    "    \n",
    "    # Parse PDFs\n",
    "pdf_files = [\"./Documents/1706.03762v7.pdf\"]\n",
    "results = parser.parse_pdfs(pdf_files)\n",
    "    \n",
    "    # Access results\n",
    "for pdf_path, content in results.items():\n",
    "        print(f\"\\nPDF: {pdf_path}\")\n",
    "        print(f\"  Text pages: {len(content.texts)}\")\n",
    "        print(f\"  Tables found: {len(content.tables)}\")\n",
    "        print(f\"  Images extracted: {len(content.images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f32424",
   "metadata": {},
   "source": [
    "## Getting the data sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2be828",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image documents \n",
    "from llama_index.core.multi_modal_llms.generic_utils import load_image_urls\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "image_documents = SimpleDirectoryReader(\"./extracted/images\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sorting the text into chunks \n",
    "text_documents = SimpleDirectoryReader(\"./extracted/texts\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f39cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Table documents \n",
    "table_documents = SimpleDirectoryReader(\"./extracted/tables\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c996115b",
   "metadata": {},
   "source": [
    "## Setting up the Qdrant client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c496c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qdrant_client\n",
    "client = qdrant_client.QdrantClient(path = \"./tmp/llama_multimodal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21cd894",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crateing the text, table and image Store \n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "text_store = QdrantVectorStore(\n",
    "    client  = client,\n",
    "    collection_name = \"text_collection\"\n",
    ")\n",
    "image_store = QdrantVectorStore(\n",
    "    client = client,\n",
    "    collection_name = \"image_collection\"\n",
    ")\n",
    "table_store = QdrantVectorStore(\n",
    "    client = client , \n",
    "    collection_name = \"table_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e084e17d",
   "metadata": {},
   "source": [
    "## Setting the Vector Store for retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dfdb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.indices import MultiModalVectorStoreIndex\n",
    "\n",
    "# Create storage context with all stores\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=text_store,\n",
    "    image_store=image_store,\n",
    "    \n",
    ")\n",
    "\n",
    "# Combine all documents for indexing\n",
    "all_documents = text_documents + image_documents + table_documents\n",
    "\n",
    "# Create the multimodal index with all documents\n",
    "index = MultiModalVectorStoreIndex.from_documents(\n",
    "    documents=all_documents,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc7d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "openai_mm_llm = OpenAIMultiModal(model=\"gpt-5\",api_key=os.getenv(\"OPENAI_API_KEY\"), max_new_tokens=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efde35a",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.query_engine import SimpleMultiModalQueryEngine\n",
    "\n",
    "qa_tmpl_str = (\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the query.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_tmpl = PromptTemplate(qa_tmpl_str)\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=openai_mm_llm, text_qa_template=qa_tmpl\n",
    ")\n",
    "\n",
    "query_str = \"What are the figures provided in the paper and what are they about ?\"\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e2d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8465c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"Explain figure 1 of the paper \"\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b66ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6050e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "image_paths = []\n",
    "for img_path in os.listdir(\"./extracted/images\"):\n",
    "    image_paths.append(str(os.path.join(\"./input_images\", img_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f04002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(image_paths):\n",
    "    images_shown = 0\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    for img_path in image_paths:\n",
    "        if os.path.isfile(img_path):\n",
    "            image = Image.open(img_path)\n",
    "\n",
    "            plt.subplot(2, 3, images_shown + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            images_shown += 1\n",
    "            if images_shown >= 9:\n",
    "                break\n",
    "\n",
    "\n",
    "plot_images(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e580d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for text_node in response.metadata[\"text_nodes\"]:\n",
    "    display_source_node(text_node, source_length=200)\n",
    "plot_images(\n",
    "    [n.metadata[\"file_path\"] for n in response.metadata[\"image_nodes\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d26ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa66f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
